# üéôÔ∏è An√°lisis: Personalizaci√≥n y Adaptaci√≥n a la Voz del Usuario

## üìã Requisito del Usuario

> "Entrenar el modelo para que se adapte a la voz del usuario, teniendo en cuenta acentos y maneras de hablar. Proceso de calibraci√≥n donde el usuario lee un texto, el modelo analiza su voz y se adapta."

---

## üîç Investigaci√≥n Realizada

### 1. **Fine-tuning de Whisper (Adaptaci√≥n completa del modelo)**

#### **LoRA (Low-Rank Adaptation)** ‚≠ê M√°s prometedor
- **Qu√© es:** Congela pesos originales y entrena solo matrices peque√±as de bajo rango
- **Ventajas:**
  - Solo 1% de par√°metros entrenables (~60MB vs 6GB)
  - Funciona con 8GB GPU (vs 40GB+ para full fine-tuning)
  - 5x m√°s r√°pido que fine-tuning completo
  - Checkpoints muy peque√±os (f√°cil distribuci√≥n)
- **Tiempo:** 6-8 horas con dataset de 12 horas (Common Voice)
- **Repositorio principal:** [Vaibhavs10/fast-whisper-finetuning](https://github.com/Vaibhavs10/fast-whisper-finetuning)
- **Librer√≠as:** `peft`, `bitsandbytes`, `accelerate`, `transformers`

#### **Prompt Tuning para Target-Speaker ASR**
- **Qu√© es:** Usa embeddings del speaker + prompts entrenables
- **Ventajas:**
  - Solo 1% de par√°metros del modelo
  - Rendimiento comparable a full training
  - Mitiga overfitting con datos limitados
- **Paper:** [Extending Whisper with Prompt Tuning](https://arxiv.org/html/2312.08079v2)

---

### 2. **Speaker Adaptation (Adaptaci√≥n sin re-entrenar Whisper)**

#### **Speaker Embeddings (i-vectors / x-vectors)**
- **Qu√© son:** Vectores de baja dimensi√≥n que capturan caracter√≠sticas √∫nicas del speaker
- **Ventajas:**
  - No requiere re-entrenar Whisper
  - Extracci√≥n r√°pida (milisegundos)
  - Se pueden usar para filtrado/ponderaci√≥n
- **Librer√≠as:**
  - `pyannote.audio` - x-vectors con arquitectura TDNN
  - `speechbrain` - Modelos pre-entrenados en VoxCeleb
- **Uso t√≠pico:** Speaker diarization, verificaci√≥n, clustering

#### **GLoRA (Generalized Low-Rank Adaptation)**
- **Qu√© es:** Fine-tuning eficiente espec√≠fico por speaker
- **Ventajas:**
  - 20% mejora en WER con datos muy limitados
  - Eficiente en par√°metros y c√≥mputo
- **Fuente:** [Samsung Research](https://research.samsung.com/blog/Robust-Speaker-Personalisation-Using-Generalized-Low-Rank-Adaptation-for-Automatic-Speech-Recognition)

---

### 3. **Voice Enrollment / Calibration (Proceso de calibraci√≥n)**

#### **Proceso tradicional (Dragon, Windows Speech Recognition):**
1. Usuario lee texto predefinido (15-60 minutos)
2. Sistema crea perfil de voz
3. Aprende de correcciones en uso continuo
4. **Mejora:** Dram√°tica en precisi√≥n con solo 15 min

#### **Factores cr√≠ticos:**
- **Hardware:** Micr√≥fono de alta calidad (headset preferido)
- **Ambiente:** Silencioso, consistente
- **Datos:** Diversidad de fonemas, palabras comunes del usuario
- **Longitud:** 15-60 min lectura = mejora significativa

---

## üéØ **SOLUCIONES PROPUESTAS** (3 Niveles de Complejidad)

---

### **NIVEL 1: R√ÅPIDO Y SIMPLE** ‚ö° (Recomendado para empezar)

#### **Voice Enrollment B√°sico + Audio Profiling**

**Qu√© hace:**
1. Usuario lee 5-10 frases en espa√±ol (2-3 minutos)
2. Sistema analiza y guarda:
   - Nivel promedio de volumen (RMS personalizado)
   - Frecuencia fundamental (pitch)
   - Rango din√°mico
   - Patr√≥n de energ√≠a
3. Ajusta preprocesamiento en tiempo real:
   - RMS normalization personalizada
   - VAD threshold adaptativo
   - Filtrado de frecuencias personalizado

**Ventajas:**
- ‚úÖ **F√°cil implementaci√≥n** (2-3 d√≠as desarrollo)
- ‚úÖ **Sin GPU requerida**
- ‚úÖ **Sin re-entrenar Whisper**
- ‚úÖ **Mejora inmediata en robustez**
- ‚úÖ **Compatible con sistema actual**

**Desventajas:**
- ‚ùå No adapta el modelo Whisper en s√≠
- ‚ùå Mejora limitada (~5-10%)

**Implementaci√≥n:**
```python
# Pseudoc√≥digo
class VoiceProfile:
    def __init__(self):
        self.target_rms = -20  # Default
        self.pitch_range = (80, 300)  # Default
        self.vad_threshold = 0.5  # Default

    def calibrate(self, audio_samples):
        """Analiza voz del usuario y ajusta par√°metros"""
        # Calcular RMS promedio del usuario
        self.target_rms = calculate_user_rms(audio_samples)

        # Detectar pitch range
        self.pitch_range = extract_pitch_range(audio_samples)

        # Ajustar VAD threshold seg√∫n energ√≠a t√≠pica
        self.vad_threshold = adaptive_vad_threshold(audio_samples)

    def apply(self, audio_chunk):
        """Aplica perfil personalizado a audio en tiempo real"""
        audio_chunk = normalize_to_user_rms(audio_chunk, self.target_rms)
        return audio_chunk
```

**Tiempo:** 2-3 d√≠as implementaci√≥n

---

### **NIVEL 2: INTERMEDIO** ‚öôÔ∏è (Mejor relaci√≥n esfuerzo/resultado)

#### **Speaker Embeddings + Whisper Personalizado**

**Qu√© hace:**
1. Usuario lee 10 frases (5 min)
2. Extrae speaker embedding (x-vector) con `speechbrain`
3. Guarda embedding como "firma de voz"
4. En tiempo real:
   - Compara audio entrante con embedding guardado
   - Ajusta confianza de VAD seg√∫n similitud
   - Filtra mejor ruido vs. voz del usuario
5. **Opcional:** Crea dataset personalizado con las grabaciones

**Ventajas:**
- ‚úÖ **Mejora significativa** (~10-20%)
- ‚úÖ **Sin re-entrenar Whisper** (inicialmente)
- ‚úÖ **Embeddings peque√±os** (<1KB)
- ‚úÖ **Multi-usuario** (varios perfiles)
- ‚úÖ **Base para fine-tuning futuro**

**Desventajas:**
- ‚ùå Requiere instalar `speechbrain` (~500MB)
- ‚ùå M√°s complejo (1 semana desarrollo)

**Implementaci√≥n:**
```python
from speechbrain.pretrained import EncoderClassifier

class SpeakerAdaptation:
    def __init__(self):
        # Cargar modelo pre-entrenado de x-vectors
        self.encoder = EncoderClassifier.from_hparams(
            source="speechbrain/spkrec-xvect-voxceleb"
        )
        self.user_embedding = None

    def enroll_user(self, audio_samples):
        """Crea perfil de voz del usuario"""
        self.user_embedding = self.encoder.encode_batch(audio_samples)

    def verify_speaker(self, audio_chunk):
        """Verifica si audio pertenece al usuario"""
        chunk_embedding = self.encoder.encode_batch(audio_chunk)
        similarity = cosine_similarity(self.user_embedding, chunk_embedding)
        return similarity > 0.75  # Threshold
```

**Tiempo:** 5-7 d√≠as implementaci√≥n

---

### **NIVEL 3: AVANZADO** üöÄ (M√°xima precisi√≥n)

#### **LoRA Fine-tuning de Whisper**

**Qu√© hace:**
1. Proceso de calibraci√≥n extendido:
   - Usuario lee 50-100 frases (20-30 min)
   - Frases cubren diversos fonemas del espa√±ol
   - Sistema graba + guarda con transcripciones
2. Fine-tuning con LoRA:
   - Entrena modelo Whisper en voz del usuario
   - Solo 60MB de pesos adicionales
   - Preserva capacidad general del modelo
3. Carga modelo personalizado en producci√≥n

**Ventajas:**
- ‚úÖ **M√°xima precisi√≥n** (+20-40% mejora)
- ‚úÖ **Espec√≠fico para acento del usuario**
- ‚úÖ **Modelo compacto** (60MB vs 6GB)
- ‚úÖ **Preserva conocimiento general**

**Desventajas:**
- ‚ùå **Requiere GPU** (8GB+ VRAM)
- ‚ùå **Tiempo de entrenamiento** (2-4 horas por usuario)
- ‚ùå **Complejidad alta** (2-3 semanas desarrollo)
- ‚ùå **Proceso offline** (no en tiempo real)

**Arquitectura:**
```
Usuario ‚Üí Calibraci√≥n (30 min lectura)
    ‚Üì
Grabaci√≥n + Transcripciones guardadas
    ‚Üì
Fine-tuning LoRA offline (2-4 horas GPU)
    ‚Üì
Modelo personalizado (60MB)
    ‚Üì
Carga en producci√≥n ‚Üí Traducci√≥n mejorada
```

**Implementaci√≥n:**
```python
# Usando Hugging Face PEFT
from peft import LoraConfig, get_peft_model

# Configurar LoRA
lora_config = LoraConfig(
    r=8,  # Rank bajo
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],  # Capas de atenci√≥n
    lora_dropout=0.05,
    bias="none"
)

# Aplicar LoRA a Whisper
model = get_peft_model(whisper_model, lora_config)

# Fine-tuning con datos del usuario (offline)
trainer.train()

# Guardar solo pesos LoRA (~60MB)
model.save_pretrained("whisper_user_profile_marlon")
```

**Tiempo:** 2-3 semanas implementaci√≥n completa

---

## üìä **COMPARACI√ìN DE SOLUCIONES**

| Caracter√≠stica | Nivel 1: B√°sico | Nivel 2: Embeddings | Nivel 3: LoRA |
|----------------|-----------------|---------------------|---------------|
| **Mejora precisi√≥n** | +5-10% | +10-20% | +20-40% |
| **Tiempo calibraci√≥n** | 2-3 min | 5 min | 20-30 min |
| **Requiere GPU** | ‚ùå No | ‚ùå No | ‚úÖ S√≠ (8GB+) |
| **Tiempo desarrollo** | 2-3 d√≠as | 5-7 d√≠as | 2-3 semanas |
| **Complejidad** | Baja | Media | Alta |
| **Multi-usuario** | ‚úÖ S√≠ | ‚úÖ S√≠ | ‚úÖ S√≠ (1 modelo/usuario) |
| **Tama√±o perfil** | <1KB | <1KB | ~60MB |
| **Tiempo procesamiento** | 0ms | +5-10ms | 0ms (offline) |
| **Compatible ahora** | ‚úÖ 100% | ‚úÖ 90% | ‚ö†Ô∏è Requiere refactor |

---

## üéØ **RECOMENDACI√ìN: ENFOQUE H√çBRIDO (Fases)**

### **FASE 1 (Inmediato): Voice Profiling B√°sico**
- Implementar Nivel 1 (2-3 d√≠as)
- Calibraci√≥n r√°pida (2-3 min)
- Mejora modesta pero inmediata (+5-10%)
- **Sin riesgo, f√°cil rollback**

### **FASE 2 (1-2 semanas): Speaker Embeddings**
- Implementar Nivel 2 (5-7 d√≠as)
- Recolectar datos de usuarios reales
- Mejora significativa (+10-20%)
- **Base para Fase 3**

### **FASE 3 (Futuro, 2-3 meses): LoRA Fine-tuning**
- Solo si FASE 2 demuestra necesidad
- Requerir GPU cloud (AWS/GCP)
- Proceso automatizado de fine-tuning
- **M√°xima precisi√≥n (+20-40%)**

---

## üõ†Ô∏è **PROCESO DE CALIBRACI√ìN PROPUESTO (Nivel 1 + 2)**

### **Flujo de Usuario:**

```
1. Primera vez (5 minutos):
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ "Calibrar Voz" (nuevo bot√≥n en GUI) ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Instrucciones en pantalla:          ‚îÇ
   ‚îÇ "Lee las siguientes 10 frases       ‚îÇ
   ‚îÇ  en voz alta para calibrar"         ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Frase 1/10:                         ‚îÇ
   ‚îÇ "Hola, mi nombre es [nombre]"       ‚îÇ
   ‚îÇ                                     ‚îÇ
   ‚îÇ [üé§ Mant√©n ESPACIO para grabar]     ‚îÇ
   ‚îÇ                                     ‚îÇ
   ‚îÇ ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40%                ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
   (Repite para 10 frases)
                    ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ "Analizando tu voz..."              ‚îÇ
   ‚îÇ ‚è≥ Procesando...                     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ ‚úÖ "Perfil de voz creado!"           ‚îÇ
   ‚îÇ                                     ‚îÇ
   ‚îÇ Tu nombre: Marlon                   ‚îÇ
   ‚îÇ Calidad de muestra: Excelente       ‚îÇ
   ‚îÇ                                     ‚îÇ
   ‚îÇ [Continuar]                         ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

2. Uso normal:
   - Sistema carga perfil autom√°ticamente
   - Aplica ajustes personalizados
   - Usuario nota mejor precisi√≥n
```

### **10 Frases Calibraci√≥n (Espa√±ol):**

1. "Hola, mi nombre es [nombre del usuario]"
2. "Me gusta practicar ingl√©s todos los d√≠as"
3. "¬øQu√© hora es? Son las tres de la tarde"
4. "El clima est√° muy agradable hoy"
5. "Necesito comprar pan y leche en el supermercado"
6. "Mi trabajo es muy interesante y desafiante"
7. "Los n√∫meros importantes son: cero, uno, cinco, diez, veinte"
8. "Me encanta escuchar m√∫sica mientras trabajo"
9. "Voy a viajar a la playa este fin de semana"
10. "Gracias por tu ayuda, hasta luego"

**Raz√≥n de estas frases:**
- ‚úÖ Cubren vocales: a, e, i, o, u
- ‚úÖ Consonantes comunes: r, l, s, n, d, t
- ‚úÖ N√∫meros (√∫tiles para traducci√≥n)
- ‚úÖ Palabras frecuentes en conversaci√≥n
- ‚úÖ Diferentes estructuras gramaticales

---

## üíæ **ESTRUCTURA DE DATOS DEL PERFIL**

```python
# voice_profile.json
{
    "user_name": "Marlon",
    "created_at": "2025-10-21T10:30:00",
    "version": "1.0",

    # Audio characteristics
    "audio_profile": {
        "target_rms_db": -18.5,      # RMS personalizado
        "pitch_range": [95, 280],     # Hz (F0 range)
        "speaking_rate": 4.2,         # s√≠labas/segundo
        "dynamic_range": 15.3         # dB
    },

    # VAD personalization
    "vad_config": {
        "threshold": 0.42,            # Ajustado a su voz
        "min_speech_duration": 0.4    # Ajustado a su patr√≥n
    },

    # Speaker embedding (Nivel 2)
    "speaker_embedding": {
        "model": "speechbrain/xvector-voxceleb",
        "vector": [0.234, -0.112, ...],  # 512 dimensiones
        "similarity_threshold": 0.75
    },

    # Calibration metadata
    "calibration_audio": [
        {
            "phrase_id": 1,
            "text": "Hola, mi nombre es Marlon",
            "duration": 2.3,
            "quality_score": 0.95,
            "file_path": "profiles/marlon/phrase_1.wav"
        },
        # ... 9 m√°s
    ],

    # Statistics
    "usage_stats": {
        "sessions": 15,
        "total_translations": 234,
        "average_confidence": 0.87,
        "last_used": "2025-10-21T14:20:00"
    }
}
```

---

## üîÑ **INTEGRACI√ìN CON C√ìDIGO ACTUAL**

### **Cambios m√≠nimos necesarios (Nivel 1):**

```python
# translate_realtime.py

class RealtimeTranslator:
    def __init__(self, ..., voice_profile=None):
        # ... c√≥digo existente ...

        # NUEVO: Voice profiling
        self.voice_profile = voice_profile or VoiceProfile()

        # Si hay perfil, usar par√°metros personalizados
        if voice_profile:
            self.target_rms_db = voice_profile.target_rms_db
            self.vad_threshold = voice_profile.vad_threshold

    def process_audio_worker(self):
        # ... c√≥digo existente ...

        # MODIFICADO: Aplicar perfil antes de Whisper
        if self.voice_profile:
            audio_prepared = self.voice_profile.apply(audio_prepared)

        # Contin√∫a con Whisper...
```

**Impacto:** M√≠nimo (1-2 d√≠as integraci√≥n)

---

## üìà **ROADMAP PROPUESTO**

```
Semana 1-2: FASE 1 - Voice Profiling B√°sico
‚îú‚îÄ‚îÄ Dise√±o UI de calibraci√≥n
‚îú‚îÄ‚îÄ Implementar an√°lisis de audio
‚îú‚îÄ‚îÄ Guardar/cargar perfiles
‚îú‚îÄ‚îÄ Integrar con traductor
‚îî‚îÄ‚îÄ Testing con 5-10 usuarios

Semana 3-4: FASE 2 - Speaker Embeddings
‚îú‚îÄ‚îÄ Integrar SpeechBrain
‚îú‚îÄ‚îÄ Extracci√≥n de x-vectors
‚îú‚îÄ‚îÄ Sistema multi-usuario
‚îú‚îÄ‚îÄ Mejoras de VAD personalizado
‚îî‚îÄ‚îÄ Testing extensivo

Mes 3-4: FASE 3 (Opcional) - LoRA Fine-tuning
‚îú‚îÄ‚îÄ Setup infraestructura GPU
‚îú‚îÄ‚îÄ Pipeline de fine-tuning automatizado
‚îú‚îÄ‚îÄ Interfaz para entrenar modelos
‚îú‚îÄ‚îÄ Validaci√≥n de modelos personalizados
‚îî‚îÄ‚îÄ Deployment de modelos

```

---

## ‚úÖ **PR√ìXIMO PASO SUGERIDO**

**IMPLEMENTAR FASE 1 (Voice Profiling B√°sico):**

1. ‚úÖ Crear interfaz de calibraci√≥n en GUI
2. ‚úÖ Implementar an√°lisis de audio (RMS, pitch, etc.)
3. ‚úÖ Sistema de perfiles (guardar/cargar JSON)
4. ‚úÖ Integrar con flujo actual
5. ‚úÖ Testing con tu voz

**Estimado:** 2-3 d√≠as desarrollo + 1-2 d√≠as testing

¬øQuieres que empecemos con la **Fase 1** ahora mismo?

